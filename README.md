# statistical-learning-project-part2 

## Summary of Project Tasks:

The objective is to study how to use a common SVM package by implementing some classification
tasks.

Data Set: The given dataset contains 50 categories/classes. The training set has 4786 samples in the file
â€˜trainData.matâ€™, and the testing set has 1833 samples in the file â€˜testData.matâ€™. Each sample is described
by the rows of 3 different feature matrices i.e., X1 ,X2, and X3 in the corresponding file, and the category
vector is always Y. All the 3 features are normalized histograms, which means the elements are non-
negative and the sum of each feature equals to 1 (i.e.,**âˆ‘**<sub>ğ‘—</sub> ğ‘¿<sub>ğ‘˜</sub>(ğ‘–, ğ‘—) â‰¡ 1).

Step 0: Classification by individual features.
Output: The classification accuracy for the testing set in the follow cases (1) and (2).

Instructions:
(1) For each of the 3 features in the training set, ğ‘¿<sub>ğ‘˜</sub> (1 â‰¤ ğ‘˜ â‰¤ 3), train a multi-class linear SVM classifier,
i.e., **h**<sub>ğ‘˜</sub>(ğ±). Get the prediction result of **h**<sub>ğ‘˜</sub>(ğ±) based on the same feature ğ‘¿<sub>ğ‘˜</sub> in the testing set and compare to ğ’€ for computing the classification accuracy.
(2) Based on the SVM classifiers **h**<sub>ğ‘˜</sub>(ğ±), we can also obtain ğ‘<sub>ğ‘˜</sub>(ğ‘¤<sub>ğ‘–</sub>|ğ±), the (posterior) probability of sample ğ± that it belongs to the ğ‘–-th category (ğ‘¤<sub>ğ‘–</sub>) according to feature ğ‘¿<sub>ğ‘˜</sub> (1 â‰¤ ğ‘˜ â‰¤ 3). This can be done by using the parameter â€˜-b 1â€™ option in training and testing (check http://www.csie.ntu.edu.tw/~cjlin/libsvm/ for more details). Train the SVM classifiers with this option and report the classification accuracies on the testing set based on the 3 features respectively.

Step 1: Feature combination by fusion of classifiers.
Output: The classification accuracy in the testing set and compare it to that of (2) in Step 0.

Instructions: Directly combine the 3 SVM classifiers with probability output i.e., ğ‘<sub>ğ‘˜</sub>(ğ‘¤<sub>ğ‘–</sub>|ğ±) (1 â‰¤ ğ‘˜ â‰¤ 3), in (2) of Step 0. Combine the 3 classifiers by probability fusion as ğ‘<sub>ğ‘˜</sub>(ğ‘¤<sub>ğ‘–</sub>|ğ±) = **âˆ‘**<sub>ğ‘˜</sub> ğ‘<sub>ğ‘˜</sub>(ğ‘¤<sub>ğ‘–</sub>|ğ±)â„3 . The final recognition result is ğ‘¤<sub>ğ‘–*</sub> = argmax<sub>ğ‘–</sub> ğ‘<sub>ğ‘˜</sub>(ğ‘¤<sub>ğ‘–</sub>|ğ±).

Step 2: Feature combination by simple concatenation.
Output: The classification accuracy in the testing set and compare it to that of (1) in Step 0.

Instructions: Directly concatenate the 3 features ğ—<sub>ğ‘˜</sub> , 1 â‰¤ ğ‘˜ â‰¤ 3 to form a single feature, i.e. ğ— = [ğ—<sub>1</sub>, . . ., ğ—<sub>k</sub>] train a linear SVM classifier based on ğ— and obtain the classification accuracy for the testing set.
